% Chapter Template

\chapter{Dynamical systems framework} % Main chapter title

\label{dynamics} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 2. \emph{Dynamical systems}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

This chapter will review some concepts from dynamical systems and how these are being used to understand hippocampal population activity. Dynamical systems theory deals with time varying systems. It dwells on questions of how the behavior of systems evolve over time. Non-linear dynamics is a powerful analytic tool for studying complex systems. A network of neurons can be formalized as a system of differential equations, lending them to be studied in the same framework. There is the long standing idea that interesting abstract properties emerge in a population of interacting objects obeying certain local rules. This framework might prove to be useful in developing further insights into the mechanisms that give rise to emergent cognitive faculties.\\
The electrophysiology of the hippocampus has revealed several internally self generated patterns. Some of which are thought to be essential for memory consolidation. Although this is not restricted only to the hippocampus. The brain in general exhibits internally self generated activity even in the absence of external stimulus. The usual examples include the recordings form humans and animals during sleep. Although during sleep the sensory input is at a minimum, these recordings show a lot of interesting phenomena.
 
\section{Basic ideas}

\subsection{Differential equations}
Differential equations provide a convenient and straight forward technique to formalize and study dynamical systems. 
The variables in these are called state variables. Solving these equations given initial conditions we can predict the future states of the system.
[...................]
Higher order differential equations can be converted to a system if first order differential equations. 
The system of differential quations can be imagined as a vector field in the state space where a vector is assigned to every point in the state space. The vector points in the direction of change of the state variables. 

\subsection{Fixed points}
Fixed points are the states where there is no change or where the flow is zero \st{this figure shows a one dimensional system whose vector field is defined by some arbitrary function $f(x)$} When $f(x)$ is possitive the system moves towards $+ \inf$ when $f(x) = 0$, there is no change. These states are called the fixed points of the system.\st{ A fixed point is stable if a small perturbation causes the system to be pulled back to the fixed point...... An unstable fixed point  A mechanical equvivalent is atn inverted pendulum}

fig- show a two dimensional system where different types of fixed points result when the parameter $a$ is varied. These are the stable nodes star node , line of fixed points , saddle node. \\

A usual procedure used to analyze and visualize dynamical process is to compute the energy function for the system, if it exists. The standard picture is to imagine a ball rolling down the hill towards the valley. The energy landscapes can be complex in biological systems. Some systems are highly sensitive to initial conditions. fig - the ball can go either way depending on where it starts. \\
The stable fixed points of the systems are interesting since it they exist, The transients die out and the system will eventually settle to one of the stable states. These sable states are called attractors of the system. The topology of the attracctors can be very interesting and helpful in predicting the behaiour of the system in different states. \\
point. line attractor If end points of the line attractor are joined, a ring attractor is obtained which is proposed a model of the head direction system. \\
limit cycle attractor gives rise to periodic behaviour of the system, Limit cycles cannot occur in linear systems. Biological pattern generators can be understood in terms of limit cycles. Here is an exaple of modified HH model... x axis is tteh membrane voltage , y is teh potassium activation variable, Initially th model neuron is at rest correspondingf to a stable point. If a stronf pulse of current is injected in the membrane , it will take the neuron to the basin of attraction of the limit cycle and the neuron will produce rhythmic spikes. \\


\subsection{Stability analysis}
The stability of fixed points can be analyzed by linearizing the system at the fixed point and tehen applying linear stability analysis techniques. This gives correct predictions of stability .....
It can be shown that the ....hyperbolic fixed point....the stability is is correctely predicted by linearization.....\\when linear fails Layapnov stability analysis approach is usually adopted. Lyapnov funcion provides a generalized energy landscape and conservative estimate of domains of attraction . Here is an example of bistable system which has been used for modelling working memory. one of the states is the resting state, other is
 with persistant activity which could function as working memory.
\\
\subsection{Bifurcations}
Bifurcations occur when the system changes its qualitative behavior . Like when a solid changes to liquid state. Bifurcations reflect the dependence on parameteres. When a parameter is varied at a critical value the dynamics of the system might drasticlly change. In neural networks, the same network could beswitched betweendifferent regimes to implement different computations. Bifurcations are classified as local and global. Global if the bifurcation effects a large portion of the state space. 

Saddle node bifurcation occurs when a stable and an unstaable node collide and disappear. ...fig as the parameters r is varied the fixed points get closer and closer, then collide and the fixed points vanish. This can be dipicted as a bifurcation diagram. The parameter is teh independent variable and the fixed points are plotted as the dependent variable. The dotted lines indicate the unstable nodes and the stable mode.

pitchfork bifurcation occurs in symmetric systems as the parameter r is varied it loses stability and two new fixed points are created, The bifurcation diagrams are show fig.... eg - a beam with load

Hopf bifurcation occurs when a stable spiral loses its stability and a limit cycle is created. .fig--- model neuron the injected current as the aprameter , when ramu current is applied at a critical value the spiking........

\section{Attractor networks}
attractor networks have stable patterns as their attractors and depending on the initial conditions the network will settle down to one of the stable patterns. Depending on the type if attractor different kinds patterns can be achieved. It has been proposed the recurrent network in the CA3 might function as an auto-associative network........... The characteristics of the attractor determines which patterns are stable.
  
\subsection{Auto-associative network}
fig - auto associative network which has learnt a few patterns and when presented woth noisy patterns... Each pattern can be thought of as a minima in the energy landscape. Pattern completion occurs because of the recurrent synaptic architecture. When a few neurons of a certain pattern are active, then they activate others because of strong synaptic connectivity strength. The 


\subsection{Place field firing as stable states}
The basic requirement to get place cell is localized firing patterns} 
\st{Ifig - model} This is the rate model where this is the excitatory input and the firing rate is a sigmoidal function of voltage. The simulation of the model produces stable activity around the peak of the external  input even though the input is noisy [basin of attraction]... The activity tracks the input peak location as it moves. ... when extended to spiking neural network .... The connection is in the same with one addition that is is asymmetric in the direction of motion. The pyramidal cells receive information about the location of the rat simulating the entorihnal input..... The inhibitory interneurons receive theta input which is the simulated input from medial septum to the GABAergic interneurons . The simulation of the network shows thea  t as teh rat moves along the track the external excitation drifts through a group of neurons. The network tends to build a peak of activity at the location of peak of the input. Due to the asymmetry in the synaptic connections the activity spontaneously propagates forward in every theta cycle. The phase precession of the cell marked by a circle. fig

\subsection{Internal sequences in the rat hippocampus}
In the study by Pastalkova \cite{Pastalkova2008a}, multi-unit recordings were obtained form the rat hippocampus in non-sleep state. They report observation of internally generated cell assembly sequences. The animals were trained to run in a wheel during the delay period in an alternation task. The CA1 pyramidal neurons were recorded during the delay period. Some of these neuron assemblies were sequentially activated. These sequences were predictive of the time the rat spent in the wheel. The sequences were unique for different behavioral choices including the ones which were incorrect choices. Since the location of the rat was stationary, one would expect to see only place cells for that location to be active.    
[time/distance cells]
The idea of continuous attractors are used to model these cell sequences. Localized activity patterns are achieved by local excitation and long range inibition. In networks  with shift invariant structures it is possible to stabilize activity pattern on each node. Thus if we have a line of attractors in the limit of infinite nodes a continuous manifold of point attractors can be generated.  ....


\subsection{Itskov 2008, theta-mediated dynamics of spatial information in hippocampus}
\begin{itemize}
\item the correlation between position and phase of theta could be a byproduct of theta-dependent dynamics of spatial information flow (??); contrary to the view that there is an explicit temporal code.
\item the alternative view postulates that the organization of spike times is a signature of ongoing computation happening through the sequential activity of hippocampus cell assemblies within a theta cycle
\item this view is supported by the fact that the spike times show greater coordination than expected from independent temporal coding of location
\item in this study the authors tested the hypothesis that across the population of place cells, different phases within the theta cycle encode positions offset into either future or past along the rat's trajectory in a 2-D environ.
\item models predicting the activity of the place cells were fit to the CA1 place cell data. 
\item it was found that spikes on different phases of theta were best predicted by the rat's immediate future or past locations
\item theta phases corresponding to 'future' and 'past' locations are consistent across the CA1 population
\item this phenomenon might contributing to phase precession , but it can be shown that it is not a consequence of phase precession; because randomized data where phase precession of individual cells were preserved did not show this behavior

\end{itemize}
itskov  - It is a rate model with treshold adaptation. Firing of a neuron will increase its threshold this discouraging it from firing again, The connection is local excitation and global inhibition mexican hat connectivity, ----- ......\\
this is the simulateion of the model, the neurons are arranged in a  2D plane without threshold adaptation, the activity bump will stabalize. but with threshold adaptation, the activity bump shifts its peak constantly without ever stabilizing at a particular location. There is no preferred location towards which the bump will eventually settle. Trajectories for different initial conditions differ in the neurons that have adapted thresholds. So when these neurons are threshold adapted the activity tends to move away form it . The trajectories are reliable across trials even for noisy inputs. \\ another model for path integration that use continuous attractor n....[ref section]
