% Chapter Template

\chapter{Dynamical systems framework} % Main chapter title

\label{dynamics} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 2. \emph{Dynamical systems}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

This chapter will review some concepts from dynamical systems and how these are being used to understand hippocampal population activity. Dynamical systems theory deals with time varying systems. It dwells on questions of how the behavior of systems evolve over time. Non-linear dynamics is a powerful analytic tool for studying complex systems. A network of neurons can be formalized as a system of differential equations, lending them to be studied in the same framework. There is the long standing idea that interesting abstract properties emerge in a population of interacting objects obeying certain local rules. This framework might prove to be useful in developing further insights into the mechanisms that give rise to emergent cognitive faculties.\\
The electrophysiology of the hippocampus has revealed several internally self generated patterns. Some of which are thought to be essential for memory consolidation. Although this is not restricted only to the hippocampus. The brain in general exhibits internally self generated activity even in the absence of external stimulus. The usual examples include the recordings form humans and animals during sleep. Although during sleep the sensory input is at a minimum, these recordings show a lot of interesting phenomena.
 
\section{Basic ideas}

\subsection{Differential equations}
Differential equations provide a convenient and straight forward technique to formalize and study dynamical systems. 
The variables in these are called state variables. Solving these equations given initial conditions we can predict the future states of the system.
[...................]
Higher order differential equations can be converted to a system if first order differential equations. 
The system of differential quations can be imagined as a vector field in the state space where a vector is assigned to every point in the state space. The vector points in the direction of change of the state variables. 

\subsection{Fixed points}
Fixed points are the states where there is no change or where the flow is zero \st{this figure shows a one dimensional system whose vector field is defined by some arbitrary function $f(x)$} When $f(x)$ is possitive the system moves towards $+ \inf$ when $f(x) = 0$, there is no change. These states are called the fixed points of the system.\st{ A fixed point is stable if a small perturbation causes the system to be pulled back to the fixed point...... An unstable fixed point  A mechanical equvivalent is atn inverted pendulum}

fig- show a two dimensional system where different types of fixed points result when the parameter $a$ is varied. These are the stable nodes star node , line of fixed points , saddle node. \\

A usual procedure used to analyze and visualize dynamical process is to compute the energy function for the system, if it exists. The standard picture is to imagine a ball rolling down the hill towards the valley. The energy landscapes can be complex in biological systems. Some systems are highly sensitive to initial conditions. fig - the ball can go either way depending on where it starts. \\
The stable fixed points of the systems are interesting since it they exist, The transients die out and the system will eventually settle to one of the stable states. These sable states are called attractors of the system. The topology of the attracctors can be very interesting and helpful in predicting the behaiour of the system in different states. \\
point. line attractor If end points of the line attractor are joined, a ring attractor is obtained which is proposed a model of the head direction system. \\
limit cycle attractor gives rise to periodic behaviour of the system, Limit cycles cannot occur in linear systems. Biological pattern generators can be understood in terms of limit cycles. Here is an exaple of modified HH model... x axis is tteh membrane voltage , y is teh potassium activation variable, Initially th model neuron is at rest correspondingf to a stable point. If a stronf pulse of current is injected in the membrane , it will take the neuron to the basin of attraction of the limit cycle and the neuron will produce rhythmic spikes. \\


\subsection{Stability analysis}
The stability of fixed points can be analyzed by linearizing the system at the fixed point and tehen applying linear stability analysis techniques. This gives correct predictions of stability .....
It can be shown that the ....hyperbolic fixed point....the stability is is correctely predicted by linearization.....\\when linear fails Layapnov stability analysis approach is usually adopted. Lyapnov funcion provides a generalized energy landscape and conservative estimate of domains of attraction . Here is an example of bistable system which has been used for modelling working memory. one of the states is the resting state, other is
 with persistant activity which could function as working memory.
\\
\subsection{Bifurcations}
Bifurcations occur when the system changes its qualitative behavior . Like when a solid changes to liquid state. Bifurcations reflect the dependence on parameteres. When a parameter is varied at a critical value the dynamics of the system might drasticlly change. In neural networks, the same network could beswitched betweendifferent regimes to implement different computations. Bifurcations are classified as local and global. Global if the bifurcation effects a large portion of the state space. 

Saddle node bifurcation occurs when a stable and an unstaable node collide and disappear. ...fig as the parameters r is varied the fixed points get closer and closer, then collide and the fixed points vanish. This can be dipicted as a bifurcation diagram. The parameter is teh independent variable and the fixed points are plotted as the dependent variable. The dotted lines indicate the unstable nodes and the stable mode.

pitchfork bifurcation occurs in symmetric systems as the parameter r is varied it loses stability and two new fixed points are created, The bifurcation diagrams are show fig.... eg - a beam with load

Hopf bifurcation occurs when a stable spiral loses its stability and a limit cycle is created. .fig--- model neuron the injected current as the aprameter , when ramu current is applied at a critical value the spiking........

\section{Attractor networks}
attractor networks have stable patterns as their attractors and depending on the initial conditions the network will settle down to one of the stable patterns. Depending on the type if attractor different kinds patterns can be achieved. It has been proposed the recurrent network in the CA3 might function as an auto-associative network........... The characteristics of the attractor determines which patterns are stable.
This type of continuous attractor dynamics has been proposed as a mechanism for path integration (sec. \ref{pathIntgr}, p. \pageref{pathIntgr}). Localized activity patterns are achieved by local excitation and long range inhibition. In networks  with shift invariant structures it is possible to stabilize activity pattern on each node. Thus if we have a line of attractors in the limit of infinite nodes a continuous manifold of point attractors can be generated.

\subsection{Auto-associative network}
fig - auto associative network which has learnt a few patterns and when presented woth noisy patterns... Each pattern can be thought of as a minima in the energy landscape. Pattern completion occurs because of the recurrent synaptic architecture. When a few neurons of a certain pattern are active, then they activate others because of strong synaptic connectivity strength. The 


\subsection{Models of place selectivity and phase precession}
The basic requirement to get place cell is localized firing patterns, so that the this pattern might then be utilized to encode distinct locations in the physical space. Second requirement is to have a mechanism by which this localized activity can be conveniently updated as the animal traverses in the environment.\\

Contrary to the view that there is an explicit temporal code (sec. \ref{placeCells} p. \pageref{placeCells}), it has been suggested that the correlation between position and phase of theta could be explained as a consequence of sequential computation occurring within a theta cycle. Across the population of place cells, different phases the theta cycle encode positions offset into either future or past along the rat's trajectory \cite{Itskov2008}. The past and future locations  robustly predict the CA1 place cell activity at different phases. This indicates that the information content in the cell activity at different phases of theta is actually correlated with the past and future locations of the animal. It was also show that this phenomena is not a direct consequence of phase precession, rather might actually be a causing the observed phase precession. \\

Tsodyks \cite{Tsodyks1996} proposed a model proposing possible mechanisms through with place cell selectivity is achieved through a specific synaptic connectivity between neurons reflecting the distances between their place field peaks in the environment. In the presence of global inhibition this architecture results to attractor dynamics. External input with weak selectivity is sufficient to steer the network into the one of the basins of attraction resulting in stable localized activity. The activity tracks the input peak location as it moves. With the addition of asymmetric synaptic strengths in the direction of motion phase precession effect is observed. Hence the phase precession could be a manifestation of the inherent asymmetry in the synaptic connections. The inhibitory interneurons in the model network receive theta input which is the simulated input from medial septum to the GABAergic interneurons. The simulation of the network shows that as the rat moves along the track the external excitation drifts through a group of neurons. Due to the asymmetry in the synaptic connections the activity spontaneously propagates forward in every theta cycle. \\  

\subsection{Internal sequences in the rat hippocampus}
In the study by Pastalkova \cite{Pastalkova2008a}, multi-unit recordings were obtained form the rat hippocampus in non-sleep state. They report observation of internally self sustained cell assembly sequences. The animals were trained to run in a wheel during the delay period in an alternation task. The CA1 pyramidal neurons were recorded during the delay period. Some of these neuron assemblies were sequentially activated. These sequences were predictive of the time the rat spent in the wheel upto 20 seconds \cite{Itskov2011a}. The sequences were unique for different behavioral choices including the ones which were incorrect choices. Since the location of the rat was stationary, one would expect to see only place cells for that location to be active.  \\  
[time/distance cells]
It has been proposed that this could be a means by which the networks keeps track of time elapsed. A model was proposed suggesting a possible mechanism for the generation of cell sequences in a network with no strong inputs.  The two critical ingredients of the model are adaptive thresholds and Mexican hat synaptic connectivity. In the model, every spike fired by the neuron will result in the increase of its spiking threshold. This threshold then exponentially decays to it default value with a time constant in the order of seconds. Thus a neuron gets increasingly discouraged to fire as its firing rate increases, which will eventually silence the neuron.The Mexican hat type connectivity ensures that the activity remains localize to a small number of neighboring neurons. The symmetry in the connectivity is broken by introducing uncorrelated noise in the connectivity matrix. In fact, to ensure that the dynamics displayed by the model is not just a result of the perfect synaptic tuning; the strength of the correlated Mexican hat connectivity was chosen to be weaker as compared to that of the heterogeneous component. This model generates a continuum of bump attractors, for the network, this implies that if the bump were to be moved laterally by some means, it would stabilize in the new position.  The introduction of threshold adaptation will result in the increase of the thresholds of neurons participating in the localized activity. Gradually, on the time scale of seconds (i.e. the time scale of threshold relaxation), this bump will lose its stability as the neurons become quite due high values of threshold. Assuming the input noise levels are low, the heterogeneity in the network connectivity will dictate the next position of the stable bump, which will remain so until it is destabilized again by the same mechanism. The bump in essence is moving away from the neurons with recently updated thresholds. In this setting, activity bump shifts its peak constantly without ever stabilizing at a particular location. Thus the model exhibits self generated sequential activation of cells, captured by the bump constantly moving along continuous trajectories in the state space. The model produces reliable trajectories even with weakly noisy input, provided that it starts with the same initial conditions. Hence, the similar heterogeneity and threshold levels across trials provide identical contexts which results in reproducible behavior. It was also shown that these sequences can be inherited by succeeding layer of neurons without recurrent connections receiving sparse feed-forward input from the layer with recurrent connectivity.Since the CA1 region does not have recurrent connectivity and the sequences were observed in CA1, it is possible that they are inherited form sequences are generated elsewhere.


Further as 
The idea of continuous attractors are used to model these cell sequences.   ....


